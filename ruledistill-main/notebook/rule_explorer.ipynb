{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìö Rule & Question Explorer\n",
    "\n",
    "Interactive notebook to explore questions, results, and rules from the self-regulated pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Configuration\n",
    "CHECKPOINT_DIR = \"/root/hsin_research/ruledistill-main/data/checkpoints\"\n",
    "DATASET_PATH = \"/root/hsin_research/FinQA-main/dataset/train.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pre_text': ['interest rate to a variable interest rate based on the three-month libor plus 2.05% ( 2.05 % ) ( 2.34% ( 2.34 % ) as of october 31 , 2009 ) .',\n",
       "  'if libor changes by 100 basis points , our annual interest expense would change by $ 3.8 million .',\n",
       "  'foreign currency exposure as more fully described in note 2i .',\n",
       "  'in the notes to consolidated financial statements contained in item 8 of this annual report on form 10-k , we regularly hedge our non-u.s .',\n",
       "  'dollar-based exposures by entering into forward foreign currency exchange contracts .',\n",
       "  'the terms of these contracts are for periods matching the duration of the underlying exposure and generally range from one month to twelve months .',\n",
       "  'currently , our largest foreign currency exposure is the euro , primarily because our european operations have the highest proportion of our local currency denominated expenses .',\n",
       "  'relative to foreign currency exposures existing at october 31 , 2009 and november 1 , 2008 , a 10% ( 10 % ) unfavorable movement in foreign currency exchange rates over the course of the year would not expose us to significant losses in earnings or cash flows because we hedge a high proportion of our year-end exposures against fluctuations in foreign currency exchange rates .',\n",
       "  'the market risk associated with our derivative instruments results from currency exchange rate or interest rate movements that are expected to offset the market risk of the underlying transactions , assets and liabilities being hedged .',\n",
       "  'the counterparties to the agreements relating to our foreign exchange instruments consist of a number of major international financial institutions with high credit ratings .',\n",
       "  'we do not believe that there is significant risk of nonperformance by these counterparties because we continually monitor the credit ratings of such counterparties .',\n",
       "  'while the contract or notional amounts of derivative financial instruments provide one measure of the volume of these transactions , they do not represent the amount of our exposure to credit risk .',\n",
       "  'the amounts potentially subject to credit risk ( arising from the possible inability of counterparties to meet the terms of their contracts ) are generally limited to the amounts , if any , by which the counterparties 2019 obligations under the contracts exceed our obligations to the counterparties .',\n",
       "  'the following table illustrates the effect that a 10% ( 10 % ) unfavorable or favorable movement in foreign currency exchange rates , relative to the u.s .',\n",
       "  'dollar , would have on the fair value of our forward exchange contracts as of october 31 , 2009 and november 1 , 2008: .'],\n",
       " 'post_text': ['fair value of forward exchange contracts after a 10% ( 10 % ) unfavorable movement in foreign currency exchange rates asset ( liability ) .',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '$ 20132 $ ( 9457 ) fair value of forward exchange contracts after a 10% ( 10 % ) favorable movement in foreign currency exchange rates liability .',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '$ ( 6781 ) $ ( 38294 ) the calculation assumes that each exchange rate would change in the same direction relative to the u.s .',\n",
       "  'dollar .',\n",
       "  'in addition to the direct effects of changes in exchange rates , such changes typically affect the volume of sales or the foreign currency sales price as competitors 2019 products become more or less attractive .',\n",
       "  'our sensitivity analysis of the effects of changes in foreign currency exchange rates does not factor in a potential change in sales levels or local currency selling prices. .'],\n",
       " 'filename': 'ADI/2009/page_49.pdf',\n",
       " 'table_ori': [['', 'October 31, 2009', 'November 1, 2008'],\n",
       "  ['Fair value of forward exchange contracts asset (liability)',\n",
       "   '$6,427',\n",
       "   '$(23,158)'],\n",
       "  ['Fair value of forward exchange contracts after a 10% unfavorable movement in foreign currency exchange rates asset (liability)',\n",
       "   '$20,132',\n",
       "   '$(9,457)'],\n",
       "  ['Fair value of forward exchange contracts after a 10% favorable movement in foreign currency exchange rates liability',\n",
       "   '$(6,781)',\n",
       "   '$(38,294)']],\n",
       " 'table': [['', 'october 31 2009', 'november 1 2008'],\n",
       "  ['fair value of forward exchange contracts asset ( liability )',\n",
       "   '$ 6427',\n",
       "   '$ -23158 ( 23158 )'],\n",
       "  ['fair value of forward exchange contracts after a 10% ( 10 % ) unfavorable movement in foreign currency exchange rates asset ( liability )',\n",
       "   '$ 20132',\n",
       "   '$ -9457 ( 9457 )'],\n",
       "  ['fair value of forward exchange contracts after a 10% ( 10 % ) favorable movement in foreign currency exchange rates liability',\n",
       "   '$ -6781 ( 6781 )',\n",
       "   '$ -38294 ( 38294 )']],\n",
       " 'qa': {'question': 'what is the the interest expense in 2009?',\n",
       "  'answer': '380',\n",
       "  'explanation': '',\n",
       "  'ann_table_rows': [],\n",
       "  'ann_text_rows': [1],\n",
       "  'steps': [{'op': 'divide1-1', 'arg1': '100', 'arg2': '100', 'res': '1%'},\n",
       "   {'op': 'divide1-2', 'arg1': '3.8', 'arg2': '#0', 'res': '380'}],\n",
       "  'program': 'divide(100, 100), divide(3.8, #0)',\n",
       "  'gold_inds': {'text_1': 'if libor changes by 100 basis points , our annual interest expense would change by $ 3.8 million .'},\n",
       "  'exe_ans': 3.8,\n",
       "  'tfidftopn': {'text_14': 'dollar , would have on the fair value of our forward exchange contracts as of october 31 , 2009 and november 1 , 2008: .',\n",
       "   'text_0': 'interest rate to a variable interest rate based on the three-month libor plus 2.05% ( 2.05 % ) ( 2.34% ( 2.34 % ) as of october 31 , 2009 ) .'},\n",
       "  'program_re': 'divide(3.8, divide(100, 100))',\n",
       "  'model_input': [['text_0',\n",
       "    'interest rate to a variable interest rate based on the three-month libor plus 2.05% ( 2.05 % ) ( 2.34% ( 2.34 % ) as of october 31 , 2009 ) .'],\n",
       "   ['text_1',\n",
       "    'if libor changes by 100 basis points , our annual interest expense would change by $ 3.8 million .'],\n",
       "   ['text_14',\n",
       "    'dollar , would have on the fair value of our forward exchange contracts as of october 31 , 2009 and november 1 , 2008: .']]},\n",
       " 'id': 'ADI/2009/page_49.pdf-1',\n",
       " 'table_retrieved': [{'score': -0.6207679510116577, 'ind': 'table_1'},\n",
       "  {'score': -0.8948984742164612, 'ind': 'table_2'}],\n",
       " 'text_retrieved': [{'score': 1.251369595527649, 'ind': 'text_1'},\n",
       "  {'score': 0.6589734554290771, 'ind': 'text_0'},\n",
       "  {'score': -0.1914736032485962, 'ind': 'text_14'}],\n",
       " 'table_retrieved_all': [{'score': -0.6207679510116577, 'ind': 'table_1'},\n",
       "  {'score': -0.8948984742164612, 'ind': 'table_2'},\n",
       "  {'score': -1.2129878997802734, 'ind': 'table_3'},\n",
       "  {'score': -2.9782934188842773, 'ind': 'table_0'}],\n",
       " 'text_retrieved_all': [{'score': 1.251369595527649, 'ind': 'text_1'},\n",
       "  {'score': 0.6589734554290771, 'ind': 'text_0'},\n",
       "  {'score': -0.1914736032485962, 'ind': 'text_14'},\n",
       "  {'score': -1.0945320129394531, 'ind': 'text_47'},\n",
       "  {'score': -1.4916260242462158, 'ind': 'text_24'},\n",
       "  {'score': -1.5615578889846802, 'ind': 'text_12'},\n",
       "  {'score': -1.572263479232788, 'ind': 'text_15'},\n",
       "  {'score': -1.6337369680404663, 'ind': 'text_5'},\n",
       "  {'score': -1.678298830986023, 'ind': 'text_3'},\n",
       "  {'score': -1.6905218362808228, 'ind': 'text_6'},\n",
       "  {'score': -1.9114893674850464, 'ind': 'text_46'},\n",
       "  {'score': -1.914547324180603, 'ind': 'text_7'},\n",
       "  {'score': -1.955027461051941, 'ind': 'text_8'},\n",
       "  {'score': -2.0304598808288574, 'ind': 'text_49'},\n",
       "  {'score': -2.0383174419403076, 'ind': 'text_13'},\n",
       "  {'score': -2.112241268157959, 'ind': 'text_10'},\n",
       "  {'score': -2.1439552307128906, 'ind': 'text_11'},\n",
       "  {'score': -2.2258567810058594, 'ind': 'text_4'},\n",
       "  {'score': -2.409395694732666, 'ind': 'text_48'},\n",
       "  {'score': -2.6092159748077393, 'ind': 'text_9'},\n",
       "  {'score': -2.6313436031341553, 'ind': 'text_2'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_16'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_17'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_18'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_19'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_20'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_21'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_22'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_23'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_25'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_26'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_27'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_28'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_29'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_30'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_31'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_32'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_33'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_34'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_35'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_36'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_37'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_38'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_39'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_40'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_41'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_42'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_43'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_44'},\n",
       "  {'score': -2.932347536087036, 'ind': 'text_45'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read out the first item in the list of objects in the train.json\n",
    "import json\n",
    "with open(DATASET_PATH, 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "first_item = data[0]\n",
    "first_item\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "‚úì Loaded 50 question results\n",
      "‚úì Loaded 10 rulebook versions\n",
      "‚úì Loaded 10 batch metrics\n",
      "\n",
      "Available fields: ['reasoning', 'answer', 'rules_applied', 'success', 'raw_response', 'idx', 'question', 'ground_truth', 'batch_num']\n"
     ]
    }
   ],
   "source": [
    "def load_all_results(checkpoint_dir):\n",
    "    \"\"\"Load all batch results into a list.\"\"\"\n",
    "    results = []\n",
    "    result_files = sorted(Path(checkpoint_dir).glob(\"results_batch_*.jsonl\"))\n",
    "    \n",
    "    for rf in result_files:\n",
    "        batch_num = int(rf.stem.split('_')[-1])\n",
    "        with open(rf, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    item = json.loads(line)\n",
    "                    item['batch_num'] = batch_num\n",
    "                    results.append(item)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def load_rulebook(filepath):\n",
    "    \"\"\"Parse rulebook XML and return list of rules.\"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            content = f.read()\n",
    "        root = ET.fromstring(content)\n",
    "        rules = []\n",
    "        for rule in root.findall('.//Rule'):\n",
    "            rules.append({\n",
    "                'id': rule.get('id', ''),\n",
    "                'type': rule.get('type', ''),\n",
    "                'source': rule.get('source', ''),\n",
    "                'trigger': rule.find('Trigger').text if rule.find('Trigger') is not None else '',\n",
    "                'action': rule.find('Action').text if rule.find('Action') is not None else ''\n",
    "            })\n",
    "        return rules\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filepath}: {e}\")\n",
    "        return []\n",
    "\n",
    "def load_all_rulebooks(checkpoint_dir):\n",
    "    \"\"\"Load all rulebook versions.\"\"\"\n",
    "    rulebooks = {}\n",
    "    rb_files = sorted(Path(checkpoint_dir).glob(\"rulebook_batch_*.xml\"))\n",
    "    for rf in rb_files:\n",
    "        batch_num = int(rf.stem.split('_')[-1])\n",
    "        rulebooks[batch_num] = load_rulebook(str(rf))\n",
    "    return rulebooks\n",
    "\n",
    "def load_metrics(checkpoint_dir):\n",
    "    \"\"\"Load metrics history.\"\"\"\n",
    "    metrics_file = os.path.join(checkpoint_dir, \"metrics.jsonl\")\n",
    "    metrics = []\n",
    "    if os.path.exists(metrics_file):\n",
    "        with open(metrics_file, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    metrics.append(json.loads(line))\n",
    "    return metrics\n",
    "\n",
    "# Load everything\n",
    "print(\"Loading data...\")\n",
    "all_results = load_all_results(CHECKPOINT_DIR)\n",
    "all_rulebooks = load_all_rulebooks(CHECKPOINT_DIR)\n",
    "all_metrics = load_metrics(CHECKPOINT_DIR)\n",
    "\n",
    "print(f\"‚úì Loaded {len(all_results)} question results\")\n",
    "print(f\"‚úì Loaded {len(all_rulebooks)} rulebook versions\")\n",
    "print(f\"‚úì Loaded {len(all_metrics)} batch metrics\")\n",
    "\n",
    "# Show sample keys\n",
    "if all_results:\n",
    "    print(f\"\\nAvailable fields: {list(all_results[0].keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Question Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522543a9c75a4a04bd284eed8829e3e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntSlider(value=0, continuous_update=False, description='Question #:', layout=Layout(width='80%‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"border: 2px solid green; border-radius: 10px; padding: 15px; margin: 10px 0; background: #f9f9f9;\">\n",
       "        <h3 style=\"margin-top: 0;\">Question #0 (Batch 0) ‚úÖ CORRECT</h3>\n",
       "\n",
       "        <div style=\"background: #fff; padding: 10px; border-radius: 5px; margin: 10px 0;\">\n",
       "            <strong>üìù Question:</strong><br>\n",
       "            <p style=\"font-size: 14px;\">what is the the interest expense in 2009?</p>\n",
       "        </div>\n",
       "\n",
       "        <div style=\"display: flex; gap: 20px;\">\n",
       "            <div style=\"flex: 1; background: #e8f5e9; padding: 10px; border-radius: 5px;\">\n",
       "                <strong>üéØ Ground Truth:</strong><br>\n",
       "                <code style=\"font-size: 16px;\">3.8</code>\n",
       "            </div>\n",
       "            <div style=\"flex: 1; background: #e8f5e9; padding: 10px; border-radius: 5px;\">\n",
       "                <strong>ü§ñ Model Answer:</strong><br>\n",
       "                <code style=\"font-size: 16px;\">0</code>\n",
       "            </div>\n",
       "        </div>\n",
       "\n",
       "        <div style=\"margin-top: 10px; background: #e3f2fd; padding: 8px; border-radius: 5px;\">\n",
       "            <strong>üìò Rules Applied:</strong> None parsed\n",
       "        </div>\n",
       "\n",
       "        <details style=\"margin-top: 15px;\">\n",
       "            <summary style=\"cursor: pointer; font-weight: bold;\">üí≠ Model Reasoning (click to expand)</summary>\n",
       "            <pre style=\"background: #fff3e0; padding: 10px; border-radius: 5px; max-height: 400px; overflow-y: auto; font-size: 12px; white-space: pre-wrap;\">Per the given context, if LIBOR changes by 100 basis points, the annual interest expense would change by $3.8 million. However, to find the interest expense in 2009, we would need the actual LIBOR rate for 2009 and the initial interest expense or more specific details about the financial instrument in question. Since this information is not provided and there are no rules specified in the rulebook, we must rely on general financial reasoning. Unfortunately, without the initial interest expense or the LIBOR rate for 2009, we cannot accurately calculate the interest expense for that year. Given the lack of specific data and rules, we cannot proceed with a precise calculation.</pre>\n",
       "        </details>\n",
       "\n",
       "        <details style=\"margin-top: 10px;\">\n",
       "            <summary style=\"cursor: pointer; font-weight: bold;\">üìÑ Full Raw Response (click to expand)</summary>\n",
       "            <pre style=\"background: #f5f5f5; padding: 10px; border-radius: 5px; max-height: 400px; overflow-y: auto; font-size: 11px; white-space: pre-wrap;\">&lt;Response&gt;\n",
       "&lt;Reasoning&gt;Per the given context, if LIBOR changes by 100 basis points, the annual interest expense would change by $3.8 million. However, to find the interest expense in 2009, we would need the actual LIBOR rate for 2009 and the initial interest expense or more specific details about the financial instrument in question. Since this information is not provided and there are no rules specified in the rulebook, we must rely on general financial reasoning. Unfortunately, without the initial interest expense or the LIBOR rate for 2009, we cannot accurately calculate the interest expense for that year. Given the lack of specific data and rules, we cannot proceed with a precise calculation.&lt;/Reasoning&gt;\n",
       "&lt;Answer&gt;0&lt;/Answer&gt;\n",
       "&lt;RulesApplied&gt;none&lt;/RulesApplied&gt;\n",
       "&lt;/Response&gt;</pre>\n",
       "        </details>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import html as html_lib\n",
    "\n",
    "def display_question(idx):\n",
    "    \"\"\"Display a single question with all details.\"\"\"\n",
    "    if idx < 0 or idx >= len(all_results):\n",
    "        print(f\"Invalid index. Valid range: 0 to {len(all_results)-1}\")\n",
    "        return\n",
    "    \n",
    "    q = all_results[idx]\n",
    "    # Use 'success' field (correct field name from data)\n",
    "    is_correct = q.get('success', False)\n",
    "    status = \"‚úÖ CORRECT\" if is_correct else \"‚ùå INCORRECT\"\n",
    "    status_color = \"green\" if is_correct else \"red\"\n",
    "    \n",
    "    # Get the answer (prediction) and reasoning\n",
    "    answer = q.get('answer', 'N/A')\n",
    "    reasoning = q.get('reasoning', '')\n",
    "    raw_response = q.get('raw_response', '')\n",
    "    rules_applied = q.get('rules_applied', [])\n",
    "    \n",
    "    # Escape HTML in content\n",
    "    reasoning_safe = html_lib.escape(str(reasoning))\n",
    "    raw_response_safe = html_lib.escape(str(raw_response))\n",
    "    \n",
    "    html = f\"\"\"\n",
    "    <div style=\"border: 2px solid {status_color}; border-radius: 10px; padding: 15px; margin: 10px 0; background: #f9f9f9;\">\n",
    "        <h3 style=\"margin-top: 0;\">Question #{idx} (Batch {q.get('batch_num', 'N/A')}) {status}</h3>\n",
    "        \n",
    "        <div style=\"background: #fff; padding: 10px; border-radius: 5px; margin: 10px 0;\">\n",
    "            <strong>üìù Question:</strong><br>\n",
    "            <p style=\"font-size: 14px;\">{html_lib.escape(str(q.get('question', 'N/A')))}</p>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"display: flex; gap: 20px;\">\n",
    "            <div style=\"flex: 1; background: #e8f5e9; padding: 10px; border-radius: 5px;\">\n",
    "                <strong>üéØ Ground Truth:</strong><br>\n",
    "                <code style=\"font-size: 16px;\">{html_lib.escape(str(q.get('ground_truth', 'N/A')))}</code>\n",
    "            </div>\n",
    "            <div style=\"flex: 1; background: {'#e8f5e9' if is_correct else '#ffebee'}; padding: 10px; border-radius: 5px;\">\n",
    "                <strong>ü§ñ Model Answer:</strong><br>\n",
    "                <code style=\"font-size: 16px;\">{html_lib.escape(str(answer))}</code>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"margin-top: 10px; background: #e3f2fd; padding: 8px; border-radius: 5px;\">\n",
    "            <strong>üìò Rules Applied:</strong> {', '.join(rules_applied) if rules_applied else 'None parsed'}\n",
    "        </div>\n",
    "        \n",
    "        <details style=\"margin-top: 15px;\">\n",
    "            <summary style=\"cursor: pointer; font-weight: bold;\">üí≠ Model Reasoning (click to expand)</summary>\n",
    "            <pre style=\"background: #fff3e0; padding: 10px; border-radius: 5px; max-height: 400px; overflow-y: auto; font-size: 12px; white-space: pre-wrap;\">{reasoning_safe}</pre>\n",
    "        </details>\n",
    "        \n",
    "        <details style=\"margin-top: 10px;\">\n",
    "            <summary style=\"cursor: pointer; font-weight: bold;\">üìÑ Full Raw Response (click to expand)</summary>\n",
    "            <pre style=\"background: #f5f5f5; padding: 10px; border-radius: 5px; max-height: 400px; overflow-y: auto; font-size: 11px; white-space: pre-wrap;\">{raw_response_safe}</pre>\n",
    "        </details>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(html))\n",
    "\n",
    "# Interactive slider\n",
    "question_slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(all_results)-1 if all_results else 0,\n",
    "    step=1,\n",
    "    description='Question #:',\n",
    "    continuous_update=False,\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def update_display(change):\n",
    "    from IPython.display import clear_output\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        display_question(question_slider.value)\n",
    "\n",
    "question_slider.observe(update_display, names='value')\n",
    "\n",
    "display(widgets.VBox([question_slider, output]))\n",
    "display_question(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Rule Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_rule(batch_num, rule_idx):\n",
    "    \"\"\"Display a single rule with styling.\"\"\"\n",
    "    if batch_num not in all_rulebooks:\n",
    "        print(f\"Batch {batch_num} not found. Available: {list(all_rulebooks.keys())}\")\n",
    "        return\n",
    "    \n",
    "    rules = all_rulebooks[batch_num]\n",
    "    if rule_idx < 0 or rule_idx >= len(rules):\n",
    "        print(f\"Invalid rule index. Valid range: 0 to {len(rules)-1}\")\n",
    "        return\n",
    "    \n",
    "    rule = rules[rule_idx]\n",
    "    \n",
    "    html = f\"\"\"\n",
    "    <div style=\"border: 2px solid #2196f3; border-radius: 10px; padding: 15px; margin: 10px 0; background: #e3f2fd;\">\n",
    "        <h3 style=\"margin-top: 0;\">üìò Rule {rule['id']} (Batch {batch_num})</h3>\n",
    "        \n",
    "        <div style=\"margin-bottom: 10px;\">\n",
    "            <span style=\"background: #1976d2; color: white; padding: 3px 8px; border-radius: 4px; font-size: 12px;\">\n",
    "                {rule['type']}\n",
    "            </span>\n",
    "            <span style=\"background: #ff9800; color: white; padding: 3px 8px; border-radius: 4px; font-size: 12px; margin-left: 5px;\">\n",
    "                {rule['source']}\n",
    "            </span>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"background: #fff; padding: 12px; border-radius: 5px; margin: 10px 0;\">\n",
    "            <strong>üéØ Trigger:</strong><br>\n",
    "            <p style=\"font-size: 14px; margin: 5px 0;\">{rule['trigger']}</p>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"background: #fff; padding: 12px; border-radius: 5px;\">\n",
    "            <strong>‚ö° Action:</strong><br>\n",
    "            <p style=\"font-size: 14px; margin: 5px 0;\">{rule['action']}</p>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(html))\n",
    "\n",
    "def display_all_rules_for_batch(batch_num):\n",
    "    \"\"\"Display all rules for a given batch.\"\"\"\n",
    "    if batch_num not in all_rulebooks:\n",
    "        print(f\"Batch {batch_num} not found.\")\n",
    "        return\n",
    "    \n",
    "    rules = all_rulebooks[batch_num]\n",
    "    print(f\"\\nüìö Rulebook for Batch {batch_num} ({len(rules)} rules)\\n\" + \"=\"*50)\n",
    "    \n",
    "    for i, rule in enumerate(rules):\n",
    "        display_rule(batch_num, i)\n",
    "\n",
    "# Get available batches\n",
    "available_batches = sorted(all_rulebooks.keys())\n",
    "print(f\"Available batches: {available_batches}\")\n",
    "\n",
    "if available_batches:\n",
    "    batch_dropdown = widgets.Dropdown(\n",
    "        options=available_batches,\n",
    "        value=available_batches[-1],\n",
    "        description='Batch:'\n",
    "    )\n",
    "    \n",
    "    max_rules = max(len(all_rulebooks[b]) for b in available_batches) - 1\n",
    "    rule_slider = widgets.IntSlider(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=max_rules,\n",
    "        step=1,\n",
    "        description='Rule #:',\n",
    "        continuous_update=False,\n",
    "        layout=widgets.Layout(width='80%')\n",
    "    )\n",
    "    \n",
    "    rule_output = widgets.Output()\n",
    "    \n",
    "    def update_rule_display(change):\n",
    "        from IPython.display import clear_output\n",
    "        with rule_output:\n",
    "            clear_output(wait=True)\n",
    "            display_rule(batch_dropdown.value, rule_slider.value)\n",
    "    \n",
    "    batch_dropdown.observe(update_rule_display, names='value')\n",
    "    rule_slider.observe(update_rule_display, names='value')\n",
    "    \n",
    "    display(widgets.VBox([batch_dropdown, rule_slider, rule_output]))\n",
    "    display_rule(available_batches[-1], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Filter Questions by Correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get correct and incorrect questions (using 'success' field)\n",
    "correct_questions = [q for q in all_results if q.get('success', False)]\n",
    "incorrect_questions = [q for q in all_results if not q.get('success', False)]\n",
    "\n",
    "print(f\"‚úÖ Correct: {len(correct_questions)}\")\n",
    "print(f\"‚ùå Incorrect: {len(incorrect_questions)}\")\n",
    "print(f\"üìä Accuracy: {len(correct_questions)/len(all_results)*100:.1f}%\" if all_results else \"No data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Browse incorrect questions only\n",
    "print(\"\\n‚ùå INCORRECT QUESTIONS BROWSER\\n\" + \"=\"*50)\n",
    "\n",
    "if incorrect_questions:\n",
    "    incorrect_slider = widgets.IntSlider(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=len(incorrect_questions)-1,\n",
    "        step=1,\n",
    "        description='Incorrect #:',\n",
    "        continuous_update=False,\n",
    "        layout=widgets.Layout(width='80%')\n",
    "    )\n",
    "    \n",
    "    incorrect_output = widgets.Output()\n",
    "    \n",
    "    def show_incorrect(idx):\n",
    "        q = incorrect_questions[idx]\n",
    "        original_idx = all_results.index(q)\n",
    "        display_question(original_idx)\n",
    "    \n",
    "    def update_incorrect(change):\n",
    "        from IPython.display import clear_output\n",
    "        with incorrect_output:\n",
    "            clear_output(wait=True)\n",
    "            show_incorrect(incorrect_slider.value)\n",
    "    \n",
    "    incorrect_slider.observe(update_incorrect, names='value')\n",
    "    display(widgets.VBox([incorrect_slider, incorrect_output]))\n",
    "    show_incorrect(0)\n",
    "else:\n",
    "    print(\"No incorrect questions found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Batch Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_batches(batch1, batch2):\n",
    "    \"\"\"Compare rules between two batches.\"\"\"\n",
    "    rules1 = {r['id']: r for r in all_rulebooks.get(batch1, [])}\n",
    "    rules2 = {r['id']: r for r in all_rulebooks.get(batch2, [])}\n",
    "    \n",
    "    ids1 = set(rules1.keys())\n",
    "    ids2 = set(rules2.keys())\n",
    "    \n",
    "    added = ids2 - ids1\n",
    "    removed = ids1 - ids2\n",
    "    common = ids1 & ids2\n",
    "    \n",
    "    changed = []\n",
    "    for rid in common:\n",
    "        if rules1[rid]['trigger'] != rules2[rid]['trigger'] or rules1[rid]['action'] != rules2[rid]['action']:\n",
    "            changed.append(rid)\n",
    "    \n",
    "    print(f\"\\nüìä Batch {batch1} ‚Üí Batch {batch2} Comparison\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"‚ûï Added: {len(added)} rules {list(added) if added else ''}\")\n",
    "    print(f\"‚ûñ Removed: {len(removed)} rules {list(removed) if removed else ''}\")\n",
    "    print(f\"‚úèÔ∏è Changed: {len(changed)} rules {changed if changed else ''}\")\n",
    "    print(f\"üìå Unchanged: {len(common) - len(changed)} rules\")\n",
    "    \n",
    "    if added:\n",
    "        print(\"\\n--- NEW RULES ---\")\n",
    "        for rid in added:\n",
    "            r = rules2[rid]\n",
    "            print(f\"\\n[{rid}] {r['type']}\")\n",
    "            print(f\"  Trigger: {r['trigger']}\")\n",
    "            print(f\"  Action: {r['action'][:100]}...\")\n",
    "\n",
    "# Compare consecutive batches\n",
    "if len(available_batches) >= 2:\n",
    "    compare_batches(available_batches[-2], available_batches[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Search Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_questions(keyword, field='question'):\n",
    "    \"\"\"Search questions containing a keyword.\"\"\"\n",
    "    matches = []\n",
    "    keyword_lower = keyword.lower()\n",
    "    \n",
    "    for i, q in enumerate(all_results):\n",
    "        text = str(q.get(field, '')).lower()\n",
    "        if keyword_lower in text:\n",
    "            matches.append((i, q))\n",
    "    \n",
    "    return matches\n",
    "\n",
    "# Example: search for percentage questions\n",
    "results = search_questions(\"percentage\")\n",
    "print(f\"Found {len(results)} questions containing 'percentage'\")\n",
    "\n",
    "# Show first few matches\n",
    "for idx, q in results[:3]:\n",
    "    status = \"‚úÖ\" if q.get('success') else \"‚ùå\"\n",
    "    print(f\"  [{idx}] {status} {q.get('question', '')[:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive search\n",
    "search_box = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Enter keyword to search...',\n",
    "    description='Search:',\n",
    "    layout=widgets.Layout(width='50%')\n",
    ")\n",
    "\n",
    "search_output = widgets.Output()\n",
    "\n",
    "def do_search(change):\n",
    "    from IPython.display import clear_output\n",
    "    with search_output:\n",
    "        clear_output(wait=True)\n",
    "        if search_box.value:\n",
    "            results = search_questions(search_box.value)\n",
    "            print(f\"Found {len(results)} matches for '{search_box.value}'\")\n",
    "            print(\"=\"*50)\n",
    "            for idx, q in results[:10]:\n",
    "                status = \"‚úÖ\" if q.get('success') else \"‚ùå\"\n",
    "                print(f\"[{idx}] {status} {q.get('question', '')[:70]}...\")\n",
    "            if len(results) > 10:\n",
    "                print(f\"... and {len(results)-10} more\")\n",
    "\n",
    "search_box.observe(do_search, names='value')\n",
    "display(widgets.VBox([search_box, search_output]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Quick Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Accuracy per batch\n",
    "if all_metrics:\n",
    "    batches = [m.get('batch_num', i) for i, m in enumerate(all_metrics)]\n",
    "    accuracies = [m.get('accuracy', 0) for m in all_metrics]\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(batches, accuracies, 'g-o', linewidth=2)\n",
    "    plt.fill_between(batches, accuracies, alpha=0.3, color='green')\n",
    "    plt.xlabel('Batch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy by Batch')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_incorrect_to_csv(output_path=\"incorrect_questions.csv\"):\n",
    "    \"\"\"Export incorrect questions to CSV.\"\"\"\n",
    "    import csv\n",
    "    \n",
    "    with open(output_path, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['batch', 'question', 'ground_truth', 'model_answer', 'reasoning'])\n",
    "        \n",
    "        for q in incorrect_questions:\n",
    "            writer.writerow([\n",
    "                q.get('batch_num', ''),\n",
    "                q.get('question', ''),\n",
    "                q.get('ground_truth', ''),\n",
    "                q.get('answer', ''),\n",
    "                q.get('reasoning', '')[:500]  # Truncate reasoning\n",
    "            ])\n",
    "    \n",
    "    print(f\"Exported {len(incorrect_questions)} incorrect questions to {output_path}\")\n",
    "\n",
    "# Uncomment to export:\n",
    "# export_incorrect_to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. View Specific Question by Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick function to view any question by index\n",
    "def view(idx):\n",
    "    \"\"\"View a specific question by index.\"\"\"\n",
    "    display_question(idx)\n",
    "\n",
    "# Example usage:\n",
    "# view(163)  # View question #163"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
