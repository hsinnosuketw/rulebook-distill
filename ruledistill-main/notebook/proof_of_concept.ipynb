{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89da2082-b50b-4469-b799-ea3a5aec23c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/bsmock/FinTabNet.c/resolve/main/FinTabNet.c-PDF_Annotations.tar.gz -O finqa_pdf.tar.gz\n",
    "# !tar -xzvf finqa_pdf.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2d86c2-846b-4572-87c2-7f0d54b2665c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download dataset from github\n",
    "# !wget https://github.com/czyssrs/FinQA/archive/refs/heads/main.zip -O finqa.zip\n",
    "# !unzip -o finqa.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf8ab38a-48d5-4c2e-946b-6a81f4f75144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6251 samples for testing.\n",
      "Sample Question 1: what is the the interest expense in 2009?\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(\n",
    "    base_url=\"https://integrate.api.nvidia.com/v1\",\n",
    "    api_key=os.environ.get(\"NVIDIA_API_KEY\")\n",
    ")\n",
    "\n",
    "# 2. Read in train.json\n",
    "def load_finqa_sample(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data  # 先取前 5 筆做實驗\n",
    "\n",
    "# 假設 train.json 與 notebook 在同一目錄\n",
    "dataset = load_finqa_sample(\"/root/hsin_research/FinQA-main/dataset/train.json\")\n",
    "\n",
    "print(f\"Loaded {len(dataset)} samples for testing.\")\n",
    "print(\"Sample Question 1:\", dataset[0]['qa']['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "160b55bc-1db0-4a3e-862c-f489e7fcbf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['question', 'answer', 'explanation', 'ann_table_rows', 'ann_text_rows', 'steps', 'program', 'gold_inds', 'exe_ans', 'tfidftopn', 'program_re', 'model_input'])\n",
      "what is the the interest expense in 2009?\n",
      "\n",
      "{'text_1': 'if libor changes by 100 basis points , our annual interest expense would change by $ 3.8 million .'}\n",
      "\n",
      "divide(100, 100), divide(3.8, #0)\n",
      "\n",
      "380\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0]['qa'].keys())\n",
    "print(dataset[0]['qa']['question'])\n",
    "print()\n",
    "print(dataset[0]['qa']['gold_inds'])\n",
    "print()\n",
    "print(dataset[0]['qa']['program'])\n",
    "print()\n",
    "print(dataset[0]['qa']['answer'])\n",
    "print()\n",
    "print(dataset[0]['qa']['ann_table_rows'])\n",
    "# divide(100, 100), divide(3.8, #0)\n",
    "#                          =>\n",
    "# divide(\n",
    "# 100\n",
    "#     ......\n",
    "# #0\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00a6f93e-0c2a-45be-8049-66cc36b5bd19",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseError",
     "evalue": "not well-formed (invalid token): line 3, column 36 (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/metatextgrad/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3579\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[3], line 33\u001b[0m\n    retriever = RuleRetriever(rulebook_xml_content)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[3], line 17\u001b[0m in \u001b[1;35m__init__\u001b[0m\n    self.root = ET.fromstring(xml_content)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/miniconda3/envs/metatextgrad/lib/python3.10/xml/etree/ElementTree.py:1347\u001b[0;36m in \u001b[0;35mXML\u001b[0;36m\n\u001b[0;31m    parser.feed(text)\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<string>\u001b[0;36m\u001b[0m\n\u001b[0;31mParseError\u001b[0m\u001b[0;31m:\u001b[0m not well-formed (invalid token): line 3, column 36\n"
     ]
    }
   ],
   "source": [
    "#  XML Rulebook\n",
    "rulebook_xml_content = \"\"\"\n",
    "<Rulebook domain=\"finqa_reasoning\">\n",
    "    <Rule id=\"01\" phase=\"generation\", confidence=\"1\", source=\"log_1\">\n",
    "        <Trigger>write program reasoning steps math operation finqa format</Trigger>\n",
    "        <Action>CRITICAL FORMATTING RULE: You must output the answer as a Domain Specific Language (DSL) program. Use functions: add(), subtract(), multiply(), divide(). Do NOT write Python code. Do NOT write explanations. Example output: \"subtract(10, 5), divide(#0, 2)\"</Action>\n",
    "    </Rule>\n",
    "    <Rule id=\"02\" phase=\"generation\", confidence=\"1\", source=\"log_1\">\n",
    "        <Trigger>basis points interest rate change bps fluctuation</Trigger>\n",
    "        <Action>KNOWLEDGE INJECTION: \"Basis points\" are a unit of measure for interest rates. 100 basis points = 1% = 0.01. If the text says \"100 basis points change results in $3.8 million\", use this ratio for calculation.</Action>\n",
    "    </Rule>\n",
    "</Rulebook>\n",
    "\"\"\"\n",
    "\n",
    "class RuleRetriever:\n",
    "    def __init__(self, xml_content):\n",
    "        self.root = ET.fromstring(xml_content)\n",
    "    \n",
    "    def retrieve(self, query, top_k=2):\n",
    "        # Simulated Vector Search\n",
    "        # TODO: Change to Embedding Cosine Similarity or Stochastic Sampling\n",
    "        query_lower = query.lower()\n",
    "        hits = []\n",
    "        for rule in self.root.findall('Rule'):\n",
    "            triggers = rule.find('Trigger').text.split()\n",
    "            \n",
    "            # Hit trigger word then recall \n",
    "            score = sum(1 for t in triggers if t in query_lower)\n",
    "            if score > 0 or rule.get('id') == 'fin_fmt_01': \n",
    "                hits.append(rule.find('Action').text)\n",
    "        return hits[:top_k]\n",
    "\n",
    "retriever = RuleRetriever(rulebook_xml_content)\n",
    "print(\"Test Retrieval:\", retriever.retrieve(\"calculate interest rate basis points\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34974918-795f-495e-9c25-38b91676be62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, model=\"meta/llama-3.3-70b-instruct\"):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.1,\n",
    "        max_tokens=128\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def run_experiment(sample, with_rules=False):\n",
    "    # build context\n",
    "    context_text = \" \".join(sample['pre_text'] + sample['post_text'])\n",
    "    table_text = str(sample['table'])                                   # store table in string format\n",
    "    question = sample['qa']['question']\n",
    "    \n",
    "    # system prompt\n",
    "    base_prompt = f\"\"\"\n",
    "    You are a financial reasoning expert. \n",
    "    Context: {context_text}\n",
    "    Table Data: {table_text}\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Task: Write a logical program steps to answer the question.\n",
    "    \"\"\"\n",
    "    print(base_prompt)\n",
    "    \n",
    "    if with_rules:\n",
    "        # rule retrieve and inject\n",
    "        rules = retriever.retrieve(question + \" write program\")\n",
    "        rules_block = \"\\n### IMPORTANT RULES (Must Follow):\\n\" + \"\\n\".join([f\"- {r}\" for r in rules])\n",
    "        final_prompt = base_prompt + rules_block\n",
    "    else:\n",
    "        final_prompt = base_prompt\n",
    "\n",
    "    # call model\n",
    "    return generate_response(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc8f8a4-aca0-4c74-9b4f-bd856536320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "source = \"https://www.canmat.org/wp-content/uploads/2019/07/Yatham-LN-2018-CANMAT-ISBD-guidelines-for-bipolar-disorder-Bipol-Disord.pdf\"  # document per local path or URL\n",
    "converter = DocumentConverter()\n",
    "result = converter.convert(source)\n",
    "print(result.document.export_to_markdown())  # output: \"## Docling Technical Report[...]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ef131d0-1928-4614-aa6b-20f9cf84489d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功映射 10 個工具。\n",
      "範例測試 (divide): 380.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from typing import List, Union\n",
    "\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the sum of two numbers.\n",
    "\n",
    "    Args:\n",
    "        a: The first number to add.\n",
    "        b: The second number to add.\n",
    "\n",
    "    Returns:\n",
    "        The sum of a and b.\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def subtract(a: float, b: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the difference between two numbers.\n",
    "\n",
    "    Args:\n",
    "        a: The number to be subtracted from (minuend).\n",
    "        b: The number to subtract (subtrahend).\n",
    "\n",
    "    Returns:\n",
    "        The difference of a minus b.\n",
    "    \"\"\"\n",
    "    return a - b\n",
    "\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the product of two numbers.\n",
    "\n",
    "    Args:\n",
    "        a: The first factor.\n",
    "        b: The second factor.\n",
    "\n",
    "    Returns:\n",
    "        The product of a and b.\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "def divide(a: float, b: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the ratio of two numbers. Handles division by zero.\n",
    "\n",
    "    Args:\n",
    "        a: The dividend (numerator).\n",
    "        b: The divisor (denominator).\n",
    "\n",
    "    Returns:\n",
    "        The result of a divided by b. Returns 0.0 if the divisor is zero to prevent crashes.\n",
    "    \"\"\"\n",
    "    if b == 0:\n",
    "        return 0.0\n",
    "    return a / b\n",
    "\n",
    "def exp(a: float, b: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the power of a number.\n",
    "\n",
    "    Args:\n",
    "        a: The base.\n",
    "        b: The exponent.\n",
    "\n",
    "    Returns:\n",
    "        The result of a raised to the power of b.\n",
    "    \"\"\"\n",
    "    return math.pow(a, b)\n",
    "\n",
    "def greater(a: float, b: float) -> bool:\n",
    "    \"\"\"\n",
    "    Compares two numbers to see if the first is larger than the second.\n",
    "\n",
    "    Args:\n",
    "        a: The first number to compare.\n",
    "        b: The second number to compare.\n",
    "\n",
    "    Returns:\n",
    "        True if a is greater than b, False otherwise.\n",
    "    \"\"\"\n",
    "    return a > b\n",
    "\n",
    "def table_sum(values: List[float]) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the total sum of a list of numerical values extracted from a table.\n",
    "\n",
    "    Args:\n",
    "        values: A list of floats to be summed.\n",
    "\n",
    "    Returns:\n",
    "        The total sum.\n",
    "    \"\"\"\n",
    "    return sum(values)\n",
    "\n",
    "def table_average(values: List[float]) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the arithmetic mean of a list of numerical values from a table.\n",
    "\n",
    "    Args:\n",
    "        values: A list of floats.\n",
    "\n",
    "    Returns:\n",
    "        The average value. Returns 0.0 if the list is empty.\n",
    "    \"\"\"\n",
    "    if not values:\n",
    "        return 0.0\n",
    "    return sum(values) / len(values)\n",
    "\n",
    "def table_max(values: List[float]) -> float:\n",
    "    \"\"\"\n",
    "    Identifies the maximum value in a list of numerical values from a table.\n",
    "\n",
    "    Args:\n",
    "        values: A list of floats.\n",
    "\n",
    "    Returns:\n",
    "        The highest value in the list.\n",
    "    \"\"\"\n",
    "    if not values:\n",
    "        return 0.0\n",
    "    return max(values)\n",
    "\n",
    "def table_min(values: List[float]) -> float:\n",
    "    \"\"\"\n",
    "    Identifies the minimum value in a list of numerical values from a table.\n",
    "\n",
    "    Args:\n",
    "        values: A list of floats.\n",
    "\n",
    "    Returns:\n",
    "        The lowest value in the list.\n",
    "    \"\"\"\n",
    "    if not values:\n",
    "        return 0.0\n",
    "    return min(values)\n",
    "\n",
    "tools_map = {\n",
    "    \"add\": add,\n",
    "    \"subtract\": subtract,\n",
    "    \"multiply\": multiply,\n",
    "    \"divide\": divide,\n",
    "    \"exp\": exp,\n",
    "    \"greater\": greater,\n",
    "    \"table_sum\": table_sum,\n",
    "    \"table_average\": table_average,\n",
    "    \"table_max\": table_max,\n",
    "    \"table_min\": table_min\n",
    "}\n",
    "\n",
    "print(f\"成功映射 {len(tools_map)} 個工具。\")\n",
    "print(f\"範例測試 (divide): {tools_map['divide'](3.8, 0.01)}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ad0c3a4-ae2c-4ca7-a95c-ea54a0c6c7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Dict, Any, Callable\n",
    "from openai import OpenAI\n",
    "\n",
    "class ProofOfConcept:\n",
    "    def __init__(\n",
    "        self, \n",
    "        client: OpenAI, \n",
    "        model: str = \"meta/llama-3.3-70b-instruct\",\n",
    "        rulebook_xml: str = \"\",\n",
    "        tools_map: Dict[str, Callable] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        初始化 Protocol-Z 執行引擎。\n",
    "        \n",
    "        Args:\n",
    "            client: OpenAI SDK client \n",
    "            model: Tool Calling Model\n",
    "            rulebook_xml: Rulebook\n",
    "            tools_map: Python 函式映射表 (例如: {\"add\": add_func})。\n",
    "        \"\"\"\n",
    "        self.client = client\n",
    "        self.model = model\n",
    "        self.rulebook_xml = rulebook_xml\n",
    "        self.tools_map = tools_map or {}\n",
    "        self.tools_schema = self._generate_tools_schema()\n",
    "\n",
    "    def _generate_tools_schema(self) -> List[Dict]:\n",
    "        \"\"\"將 tools_map 中的函式轉換為 OpenAI/NIM 要求的 JSON Schema。\"\"\"\n",
    "        # 這裡簡化處理，實際開發建議使用 pydantic 或 inspect 自動生成\n",
    "        schemas = []\n",
    "        for name, func in self.tools_map.items():\n",
    "            # 假設你已經將 Docstrings 寫好，這裡手動定義核心架構\n",
    "            schemas.append({\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": name,\n",
    "                    \"description\": func.__doc__.split(\"Args:\")[0].strip() if func.__doc__ else \"\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"a\": {\"type\": \"number\"},\n",
    "                            \"b\": {\"type\": \"number\"},\n",
    "                            \"values\": {\"type\": \"array\", \"items\": {\"type\": \"number\"}}\n",
    "                        },\n",
    "                    }\n",
    "                }\n",
    "            })\n",
    "        return schemas\n",
    "\n",
    "    def _retrieve_rules(self, query: str) -> str:\n",
    "        \"\"\"\n",
    "        [Protocol-Z 核心邏輯] \n",
    "        根據 Query 中的 Trigger 關鍵字檢索相關的 XML Rules。\n",
    "        (未來可升級為 Whitening Transformation 向量檢索)\n",
    "        \"\"\"\n",
    "        # 這裡先實作簡單的 Keyword-based 檢索作為 PoC\n",
    "        relevant_rules = []\n",
    "        # 假設你的規則庫已經被解析成 list of dict\n",
    "        # if trigger in query: relevant_rules.append(rule)\n",
    "        return f\"<Rulebook_Snippet>\\n{self.rulebook_xml[:500]}...\\n</Rulebook_Snippet>\"\n",
    "\n",
    "    def run(self, user_query: str, context: str = \"\") -> str:\n",
    "        \"\"\"\n",
    "        執行完整的推理循環：檢索規則 -> 規劃 -> 執行工具 -> 產出答案。\n",
    "        \"\"\"\n",
    "        # 1. 檢索與注入規則\n",
    "        rules_context = self._retrieve_rules(user_query)\n",
    "        \n",
    "        system_prompt = f\"\"\"\n",
    "        You are a financial advisor using the Protocol-Z reasoning framework.\n",
    "        Rules to follow:\n",
    "        {rules_context}\n",
    "        \n",
    "        Context provided from table:\n",
    "        {context}\n",
    "        \"\"\"\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_query}\n",
    "        ]\n",
    "\n",
    "        # 2. 發送請求 (NIM API)\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            tools=self.tools_schema,\n",
    "            tool_choice=\"auto\"\n",
    "        )\n",
    "\n",
    "        response_message = response.choices[0].message\n",
    "        tool_calls = response_message.tool_calls\n",
    "\n",
    "        # 3. 處理工具調用 (Iterative Loop)\n",
    "        if tool_calls:\n",
    "            messages.append(response_message)\n",
    "            \n",
    "            for tool_call in tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                function_args = json.loads(tool_call.function.arguments)\n",
    "                \n",
    "                # 執行 Python 端的工具\n",
    "                print(f\"[*] Executing Tool: {function_name} with {function_args}\")\n",
    "                function_to_call = self.tools_map[function_name]\n",
    "                function_response = function_to_call(**function_args)\n",
    "\n",
    "                messages.append({\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": str(function_response),\n",
    "                })\n",
    "            \n",
    "            # 4. 再次呼叫模型以總結結果\n",
    "            second_response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=messages,\n",
    "            )\n",
    "            return second_response.choices[0].message.content\n",
    "        \n",
    "        return response_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb141db3-1d1c-455e-8284-f334c9633d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "finqa_dataset = [dataset[i]['qa'] for i in range(len(dataset))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c055f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "with open(\"/root/hsin_research/FinQA-main/dataset/train.json\", \"r\") as file:\n",
    "    train_qa_data = json.load(file)\n",
    "\n",
    "# Save to a question-only file\n",
    "with open(\"/root/hsin_research/ruledistill-main/data/train_questions.json\", \"w\") as file:\n",
    "    json.dump([qa['qa']['question'] for qa in train_qa_data], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5bea418-7ddb-47e9-81ca-9ed4af18f4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37812960235640647\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "testset_results = []\n",
    "with open(\"/root/hsin_research/ruledistill-main/data/test_results.jsonl\") as file:\n",
    "    lines = file.readlines()\n",
    "    testset_results = [json.loads(line) for line in lines] \n",
    "\n",
    "accuracy = 0\n",
    "correct_count = 0\n",
    "for result in testset_results:\n",
    "    if result['evaluation_result'] == True:\n",
    "\n",
    "        correct_count += 1\n",
    "\n",
    "accuracy = correct_count / len(testset_results)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "239ba464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5911072362685266\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "testset_results = []\n",
    "with open(\"/root/hsin_research/ruledistill-main/data/testset_results.jsonl\") as file:\n",
    "    lines = file.readlines()\n",
    "    testset_results = [json.loads(line) for line in lines] \n",
    "\n",
    "accuracy = 0\n",
    "correct_count = 0\n",
    "for result in testset_results:\n",
    "    if result['evaluation_result'] == True:\n",
    "\n",
    "        correct_count += 1\n",
    "\n",
    "accuracy = correct_count / len(testset_results)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5f69690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5911072362685266\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "testset_results = []\n",
    "with open(\"/root/hsin_research/ruledistill-main/data/testset_results.jsonl\") as file:\n",
    "    lines = file.readlines()\n",
    "    testset_results = [json.loads(line) for line in lines] \n",
    "\n",
    "accuracy = 0\n",
    "correct_count = 0\n",
    "for result in testset_results:\n",
    "    if result['evaluation_result'] == True:\n",
    "\n",
    "        correct_count += 1\n",
    "\n",
    "accuracy = correct_count / len(testset_results)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a020fb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6155187445510026\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "testset_results = []\n",
    "with open(\"/root/hsin_research/ruledistill-main/data/testset_results_without_rules.jsonl\") as file:\n",
    "    lines = file.readlines()\n",
    "    testset_results = [json.loads(line) for line in lines] \n",
    "\n",
    "accuracy = 0\n",
    "correct_count = 0\n",
    "for result in testset_results:\n",
    "    if result['evaluation_result'] == True:\n",
    "\n",
    "        correct_count += 1\n",
    "\n",
    "accuracy = correct_count / len(testset_results)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36ab1b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7224444088945768\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "testset_results = []\n",
    "with open(\"/root/hsin_research/ruledistill-main/data/trainset_results_without_rules.jsonl\") as file:\n",
    "    lines = file.readlines()\n",
    "    testset_results = [json.loads(line) for line in lines] \n",
    "\n",
    "accuracy = 0\n",
    "correct_count = 0\n",
    "for result in testset_results:\n",
    "    if result['evaluation_result'] == True:\n",
    "\n",
    "        correct_count += 1\n",
    "\n",
    "accuracy = correct_count / len(testset_results)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metatextgrad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
